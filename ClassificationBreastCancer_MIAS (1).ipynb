{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassificationBreastCancer_MIAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDBVqYlPISkx",
        "outputId": "f46c7dc3-8394-430d-f427-e80dc7985099"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djHi7EIaIM3i"
      },
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import math\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import time\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbqw3bkFoJRJ"
      },
      "source": [
        "path_data='/content/drive/MyDrive/dataset/dataset_classes/'\n",
        "folders=glob.glob(path_data+'*')\n",
        "classes=np.array(['MISC', 'CIRC', 'CALC', 'SPIC', 'ASYM', 'ARCH', 'NORM'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Tft4sVsgJK",
        "outputId": "3bc0e107-797b-4198-b572-f16065abf589"
      },
      "source": [
        "data_id=[]\n",
        "for i in folders:\n",
        "  print(i[i.rfind('/')+1:])\n",
        "  if i==0:\n",
        "    data_id=np.array(glob.glob(i+'/m*'))\n",
        "  else:\n",
        "    images=np.array(glob.glob(i+'/m*'))\n",
        "    data_id=np.concatenate((data_id, images))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MISC\n",
            "CIRC\n",
            "CALC\n",
            "SPIC\n",
            "ASYM\n",
            "ARCH\n",
            "NORM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdQYRd4EmT-D"
      },
      "source": [
        "ids=sio.loadmat('/content/drive/MyDrive/dataset/MIAS_kaggle/sub_id.mat')['Id']\n",
        "dic=sio.loadmat('/content/drive/MyDrive/dataset/MIAS_kaggle/Dic.mat')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkA4ToNUm2Ux"
      },
      "source": [
        "def labels(key):\n",
        "  return np.where(classes==dic[key][0])[0][0]\n",
        "vecx=np.vectorize(labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw7MngbJLHK4"
      },
      "source": [
        "def remove(strg):\n",
        "  return strg[47:] \n",
        "removv=np.vectorize(remove)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYjwEsnXMALo"
      },
      "source": [
        "inds_x=removv(data_id)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0s9-rM807-t"
      },
      "source": [
        "def get_data(x_id, Fourier=False):\n",
        "  if Fourier:\n",
        "    pos=x_id.find('/')+1\n",
        "    name=x_id[:pos]+'Fourier_'+x_id[pos:]\n",
        "  else:\n",
        "    name=x_id\n",
        "  ima = cv2.imread(path_data+name)\n",
        "  lab=np.where(classes==x_id[:x_id.find('/')])[0][0]\n",
        "  return ima, int(lab)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSPd8QGyaNt6"
      },
      "source": [
        "def one_hot(vec):\n",
        "  vec = vec\n",
        "  shape = (vec.size, 7)\n",
        "  one = np.zeros(shape)\n",
        "  rows = np.arange(vec.size)\n",
        "  one[rows, vec.astype('int')] = 1\n",
        "  return one"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjbP1-WnhdXe"
      },
      "source": [
        "def get_index(inds_0):\n",
        "  subx=np.shape(inds_0)[0]\n",
        "  rando_ind=np.random.choice(subx,subx,replace=False)\n",
        "\n",
        "  idx=inds_0[rando_ind]\n",
        "\n",
        "  train_id=idx[:int(subx*0.7)]\n",
        "  valid_id=idx[int(subx*0.7):int(subx*0.85)]\n",
        "  test_id =idx[int(subx*0.85):]\n",
        "  return train_id, valid_id, test_id"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgfbQGFihk6j"
      },
      "source": [
        "def get_index2(inds_0):\n",
        "  val=vecx(inds_0)\n",
        "  train_id=[]\n",
        "  valid_id=[]\n",
        "  test_id =[]\n",
        "\n",
        "  for ix in range(7):\n",
        "    pos=np.where(val==ix)[0]\n",
        "    sz=np.shape(pos)[0]\n",
        "    rx=np.random.choice(sz,sz,replace=False)\n",
        "    pos=pos[rx]\n",
        "    train_id=np.append(train_id, inds_0[pos[:int(sz*0.6)]])\n",
        "    valid_id=np.append(valid_id, inds_0[pos[int(sz*0.6):int(sz*0.8)]])\n",
        "    test_id =np.append(test_id , inds_0[pos[int(sz*0.8):]])\n",
        "\n",
        "  stn=np.shape(train_id)[0]\n",
        "  sva=np.shape(valid_id)[0]\n",
        "  stt=np.shape(test_id)[0]\n",
        "\n",
        "  train_id=train_id[np.random.choice(stn,stn,replace=False)]\n",
        "  valid_id=valid_id[np.random.choice(sva,sva,replace=False)]\n",
        "  test_id =test_id[np.random.choice(stt,stt,replace=False)]\n",
        "  return train_id, valid_id, test_id"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHZBDzVGCWu1"
      },
      "source": [
        "kernel=[(0,0), (0,2), (1,1), (1,3), (2,0), (2,2), (3,1), (3,3)]\n",
        "def get_ima(tam, pk, ima, x_id):\n",
        "  ver=np.zeros((tam,tam))\n",
        "  hor=np.zeros((tam,tam))\n",
        "  ver[np.arange(tam)%4==kernel[pk][0],:]=1\n",
        "  hor[:,np.arange(tam)%4==kernel[pk][1]]=1\n",
        "  ima=ima[...,0]\n",
        "  ima=ima[ver*hor==1].reshape((int(tam/4),int(tam/4)))\n",
        "  if kernel[pk][0]>=2:\n",
        "    ima=np.flip(ima, axis=0)\n",
        "  ima=np.rot90(ima,kernel[pk][1])\n",
        "  lab=labels(x_id)\n",
        "  return ima, int(lab)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFBIvFSJ3nTS"
      },
      "source": [
        "def get_data_reduction(x_id, Fourier=False, pk=np.random.choice(8), aug=True):\n",
        "  tam=1024\n",
        "  if Fourier:\n",
        "    pos=x_id.find('/')+1\n",
        "    name='/content/drive/MyDrive/dataset/MIAS_kaggle/all-mias/'+x_id+'.pgm'\n",
        "  else:\n",
        "    name='/content/drive/MyDrive/dataset/MIAS_kaggle/all-mias/'+x_id+'.pgm'\n",
        "  ima = cv2.imread(name)  \n",
        "  if np.shape(ima)[0]!=tam:\n",
        "    print('Size error')\n",
        "  else:\n",
        "    if aug:\n",
        "      imaOu=np.zeros((8,int(tam/4),int(tam/4)))\n",
        "      lab2=[]\n",
        "      for pk in range(8):\n",
        "        im, la=get_ima(tam, pk, ima, x_id)\n",
        "        imaOu[pk]=im\n",
        "        lab2=np.append(lab2,la)\n",
        "      return imaOu, lab2\n",
        "    else:\n",
        "      return get_ima(tam, pk, ima, x_id)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCn3CequDeH9"
      },
      "source": [
        "xx, yy=get_data_reduction('mdb013', aug=True)\n",
        "np.shape(xx), np.shape(yy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUvb5uh25Yd7"
      },
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for i in range(8):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.title(yy[i])\n",
        "  plt.imshow(xx[i])\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05feFeTkp5rs"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AskGz9Nt65HP"
      },
      "source": [
        "def get_test_data(test_id):\n",
        "  xx_test=[]\n",
        "  yx_test=[]\n",
        "  for n, i in enumerate(test_id):\n",
        "    uno,dos=get_data(i)\n",
        "    xx_test.append(uno)\n",
        "    yx_test.append(dos)\n",
        "  test_x=np.array(xx_test)\n",
        "  test_y=np.array(yx_test)\n",
        "  return test_x, one_hot(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD6EwEwolEOX"
      },
      "source": [
        "def get_matrix(ind_0, aug=False, rgb=True):\n",
        "  sz=np.shape(ind_0)[0]\n",
        "  ima,lab=get_data_reduction(ind_0[0], aug=aug)\n",
        "  szx=np.shape(ima)\n",
        "  mat=np.zeros((sz*(1+int(aug)*7),szx[0+int(aug)],szx[1+int(aug)]))\n",
        "  labels=[]\n",
        "\n",
        "  for n,ix in enumerate(ind_0):\n",
        "    ima,lab=get_data_reduction(ix, aug=aug)\n",
        "    mat[n*(1+int(aug)*7):(n+1)*(1+int(aug)*7)]=ima\n",
        "    labels=np.append(labels, lab)\n",
        "    print(\"\\rprocess \", round((n+1)*100/sz, 2), \"%\", end=\"\")\n",
        "  mat=tf.convert_to_tensor(mat.reshape(np.shape(mat)+(1,)))\n",
        "  labels=tf.convert_to_tensor(one_hot(labels))\n",
        "  if rgb:\n",
        "    return tf.image.grayscale_to_rgb(mat), labels\n",
        "  else:\n",
        "    return mat, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CerIxlDQUErp"
      },
      "source": [
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L4AbFIYUG67"
      },
      "source": [
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTzD7BOA4-qr"
      },
      "source": [
        "train,valid,test=get_index2(ids)\n",
        "x_train, y_train=get_matrix(train, True)\n",
        "x_valid, y_valid=get_matrix(valid, True)\n",
        "x_test , y_test =get_matrix(test,  True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOtBW22pf8Wb"
      },
      "source": [
        "from tensorflow.keras import applications as ap\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w_5hKxwgURQ"
      },
      "source": [
        "Networs=['InceptionV3', 'DenseNet121', 'InceptionResNetV2', 'ResNet50V2', 'VGG19', 'Xception']\n",
        "def get_model(network, opt='adadelta', loss_name='categorical_crossentropy', input_shape=(256,256,3)):\n",
        "  try:\n",
        "    del model\n",
        "  except:\n",
        "    print('done')\n",
        "  model=Sequential()\n",
        "  if network=='ResNet50V2':\n",
        "    model.add(ap.ResNet50V2(include_top=False, input_shape=input_shape, pooling='avg', classes=7)) # The input must have 3 channels\n",
        "  if network=='EfficientNetB7':\n",
        "    model.add(ap.EfficientNetB7(include_top=False, input_shape=input_shape, pooling='avg', classes=7)) \n",
        "  if network=='InceptionResNetV2':\n",
        "    model.add(ap.InceptionResNetV2(include_top=False, input_shape=input_shape, pooling='avg', classes=7)) \n",
        "  if network=='InceptionV3':\n",
        "    model.add(ap.InceptionV3(include_top=False, input_shape=input_shape, pooling='avg', classes=7)) \n",
        "  if network=='NASNetLarge':\n",
        "    model.add(ap.NASNetLarge(include_top=False, input_shape=input_shape, pooling='avg', classes=7))\n",
        "  if network=='VGG19':\n",
        "    model.add(ap.VGG19(include_top=False, input_shape=input_shape, pooling='avg', classes=7)) \n",
        "  if network=='Xception':\n",
        "    model.add(ap.Xception(include_top=False, input_shape=input_shape, pooling='avg', classes=7))\n",
        "  if network=='DenseNet121':\n",
        "    model.add(ap.DenseNet121(include_top=False, input_shape=input_shape, pooling='avg', classes=7))\n",
        "  \n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  model.compile(optimizer=opt, loss=loss_name, metrics=['acc', tf.keras.metrics.Recall(), tf.keras.metrics.FalsePositives()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3CQnEN220kT"
      },
      "source": [
        "df = pd.DataFrame(columns=('run_n', 'network', 'optimizer', 'loss', 'epochs', 'total_parameters', 'time', 'augm', 'Class', 'TP', 'TN', 'FP', 'FN','result_mat'))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1-EjVdu6sG9"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "path2='/content/drive/MyDrive/INDIGO_MLR/CancerDeMama_MIAS/data_augmentation/'\n",
        "pathW='/content/drive/MyDrive/INDIGO_MLR/CancerDeMama_MIAS/Weights/'\n",
        "augmentation='partsRotated'\n",
        "optimizer='adadelta'\n",
        "epochs=40\n",
        "loss='categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwV3qOsJbAxk"
      },
      "source": [
        "TP=tf.keras.metrics.TruePositives()\n",
        "TN=tf.keras.metrics.TrueNegatives()\n",
        "FP=tf.keras.metrics.FalsePositives()\n",
        "FN=tf.keras.metrics.FalseNegatives()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlp0XBtm2n0b"
      },
      "source": [
        "for net in Networs:\n",
        "\n",
        "  name_0='_'.join(['clasification_t',augmentation,net,optimizer])\n",
        "  if not os.path.exists(path2+name_0+'.csv'):\n",
        "    df.to_csv(path2+name_0+'.csv')\n",
        "\n",
        "  for i in range(14,80): #Numero corridas \n",
        "    for j in [loss]: #Funciones de perdida\n",
        "      cntn=True\n",
        "      name_m='_'.join([name_0,j,'run',str(i)])  \n",
        "      print(name_m)\n",
        "\n",
        "      model=get_model(net)\n",
        "      \n",
        "      try:\n",
        "        tic = time.time()\n",
        "        results = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=epochs)\n",
        "        toc=time.time()-tic\n",
        "        model.save_weights(pathW+name_m+\"w.h5\")\n",
        "      except:\n",
        "        print('Training error')\n",
        "        cntn=False\n",
        "\n",
        "      if cntn:\n",
        "        sio.savemat(pathW+name_m+'_r.mat', results.history)\n",
        "\n",
        "        #Validation\n",
        "        y_hat=np.array(model.predict(x_test))\n",
        "        sio.savemat(pathW+name_m+'_los_8.mat',{'y_hat': y_hat})\n",
        "\n",
        "        for class_i in range(7):\n",
        "          TP.reset_state()\n",
        "          TN.reset_state()\n",
        "          FP.reset_state()\n",
        "          FN.reset_state()        \n",
        "\n",
        "          TP.update_state(y_hat[:,class_i], y_test[:,class_i])\n",
        "          TN.update_state(y_hat[:,class_i], y_test[:,class_i])\n",
        "          FP.update_state(y_hat[:,class_i], y_test[:,class_i])\n",
        "          FN.update_state(y_hat[:,class_i], y_test[:,class_i])\n",
        "          total_p=model.count_params()\n",
        "\n",
        "          #data frame\n",
        "          df2=pd.read_csv(path2+name_0+'.csv')\n",
        "          df2=df2.append({'run_n': i,\n",
        "                        'network': net,\n",
        "                        'optimizer': optimizer,\n",
        "                        'loss': 'categorical_crossentropy',\n",
        "                        'epochs': epochs,\n",
        "                        'total_parameters': total_p,\n",
        "                        'time': toc,\n",
        "                        'augm': augmentation,\n",
        "                        'Class': class_i,\n",
        "                        'TP': float(TP.result()),\n",
        "                        'TN': float(TN.result()),\n",
        "                        'FP': float(FP.result()),\n",
        "                        'FN': float(FN.result()),\n",
        "                        'result_mat': name_m+'_r.mat'} , ignore_index=True)\n",
        "          df2=df2.drop(df2.columns[:np.where(df2.columns=='run_n')[0][0]], axis=1)\n",
        "          df2.to_csv(path2+name_0+'.csv')\n",
        "        clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}